{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"C:\\\\Users\\\\ashle\\\\Desktop\\\\Korea-ggumim\\\\Datasets\\\\Korea-ggumim.csv\"\n",
    "output_path = \"C:\\\\Users\\\\ashle\\\\Desktop\\\\Korea-ggumim\\\\Datasets\\\\cleaned_data.csv\"\n",
    "garbage_dir = \"C:\\\\Users\\\\ashle\\\\Desktop\\\\Korea-ggumim\\\\Datasets\\\\Garbage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(garbage_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashle\\AppData\\Local\\Temp\\ipykernel_36856\\1758342947.py:1: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_path)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_and_clean_email(email):\n",
    "    \"\"\"\n",
    "    Validates and cleans an email address:\n",
    "    - Ensures it's valid using regex.\n",
    "    - Removes extra dots and @ symbols.\n",
    "    \"\"\"\n",
    "    email_pattern = r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$'  # Regex to validate email\n",
    "    if not re.match(email_pattern, email):\n",
    "        with open(os.path.join(garbage_dir, \"invalid_emails.txt\"), \"a\") as f:\n",
    "            f.write(email + \"\\n\")\n",
    "        return None  # Invalid email\n",
    "    return cleaned_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_nickname(nickname):\n",
    "    \"\"\"\n",
    "    Cleans a nickname:\n",
    "    - Removes control characters.\n",
    "    - Allows common symbols like ., _, and -.\n",
    "    \"\"\"\n",
    "    # Remove control characters\n",
    "    cleaned_nickname = re.sub(r'[\\x00-\\x1F\\x7F]', '', nickname)\n",
    "\n",
    "    # Log nicknames with control characters to garbage file\n",
    "    if nickname != cleaned_nickname:\n",
    "        with open(os.path.join(garbage_dir, \"invalid_nicknames.txt\"), \"a\") as f:\n",
    "            f.write(nickname + \"\\n\")\n",
    "\n",
    "    return cleaned_nickname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove duplicates\n",
    "def remove_duplicates(df):\n",
    "    global garbage\n",
    "    duplicates = df[df.duplicated()]  # Identify duplicates\n",
    "    garbage = pd.concat([garbage, duplicates])  # Store duplicate rows\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    print(f\"Duplicates removed. Remaining rows: {df.shape[0]}\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the validation and cleaning functions\n",
    "def validate_and_clean_email(email):\n",
    "    \"\"\"\n",
    "    Validates and cleans an email address:\n",
    "    - Ensures it's valid using regex.\n",
    "    - Removes extra dots and @ symbols.\n",
    "    \"\"\"\n",
    "    import re\n",
    "    email_pattern = r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$'  # Regex to validate email\n",
    "    if not re.match(email_pattern, email):\n",
    "        return None  # Invalid email\n",
    "\n",
    "    # Clean up extra dots and @ symbols\n",
    "    cleaned_email = email.replace(\"..\", \".\").replace(\"@@\", \"@\")\n",
    "\n",
    "    # Revalidate after cleaning\n",
    "    return cleaned_email if re.match(email_pattern, cleaned_email) else None\n",
    "\n",
    "\n",
    "def clean_nickname(nickname):\n",
    "    \"\"\"\n",
    "    Cleans a nickname:\n",
    "    - Removes control characters.\n",
    "    - Allows common symbols like ., _, and -.\n",
    "    \"\"\"\n",
    "    import re\n",
    "    # Remove control characters\n",
    "    cleaned_nickname = re.sub(r'[\\x00-\\x1F\\x7F]', '', nickname)\n",
    "    return cleaned_nickname\n",
    "\n",
    "# Ensure you define the functions above before applying them to the DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove outliers\n",
    "def remove_outliers(df):\n",
    "    global garbage\n",
    "    numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    for col in numerical_cols:\n",
    "        q1 = df[col].quantile(0.25)\n",
    "        q3 = df[col].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - 1.5 * iqr\n",
    "        upper_bound = q3 + 1.5 * iqr\n",
    "        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "        garbage = pd.concat([garbage, outliers])  # Store outliers\n",
    "        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]  # Keep valid data\n",
    "    print(f\"Outliers removed. Remaining rows: {df.shape[0]}\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning complete! Cleaned data saved to 'C:\\Users\\ashle\\Desktop\\Korea-ggumim\\Datasets\\cleaned_data.csv'\n",
      "Garbage files merged into 'C:\\Users\\ashle\\Desktop\\Korea-ggumim\\Datasets\\Garbage\\merged_garbage.txt'\n"
     ]
    }
   ],
   "source": [
    "# Save the cleaned data to a new CSV\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "# Merge garbage files into one\n",
    "merged_garbage_file = os.path.join(garbage_dir, \"merged_garbage.txt\")\n",
    "with open(merged_garbage_file, \"w\") as outfile:\n",
    "    for garbage_file in os.listdir(garbage_dir):\n",
    "        if garbage_file.endswith(\".txt\") or garbage_file.endswith(\".csv\"):\n",
    "            with open(os.path.join(garbage_dir, garbage_file), \"r\") as infile:\n",
    "                outfile.write(f\"\\n--- {garbage_file} ---\\n\")\n",
    "                outfile.write(infile.read())\n",
    "\n",
    "print(f\"Cleaning complete! Cleaned data saved to '{output_path}'\")\n",
    "print(f\"Garbage files merged into '{merged_garbage_file}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Define README content\n",
    "readme_content = \"\"\"\n",
    "# Korea Ggumim Data Cleaning Project\n",
    "\n",
    "This project involves cleaning a dataset containing user information from Korea Ggumim. The tasks performed include:\n",
    "\n",
    "1. Cleaning and validating email addresses.\n",
    "2. Cleaning nicknames to remove control characters while retaining common symbols.\n",
    "\n",
    "## Files in the Project\n",
    "\n",
    "- `raw_data.csv`: The original dataset.\n",
    "- `cleaned_data.csv`: The cleaned dataset.\n",
    "- `garbage_files`: Temporary files created during processing.\n",
    "\n",
    "## Steps in the Cleaning Process\n",
    "\n",
    "1. Validate email addresses:\n",
    "    - Remove invalid emails.\n",
    "    - Strip extra dots and symbols.\n",
    "2. Clean nicknames:\n",
    "    - Remove control characters.\n",
    "    - Allow common symbols like `.`, `_`, and `-`.\n",
    "\n",
    "## How to Run\n",
    "\n",
    "1. Ensure all dependencies are installed:\n",
    "    ```\n",
    "    pip install pandas numpy\n",
    "    ```\n",
    "2. Run the main script:\n",
    "    ```\n",
    "    python clean_data.py\n",
    "    ```\n",
    "3. The cleaned dataset will be saved as `cleaned_data.csv`.\n",
    "\n",
    "## Garbage Files\n",
    "\n",
    "Temporary files generated during cleaning can be found in the `garbage_files/` directory. These can be merged or deleted after the process.\n",
    "\n",
    "## Notes\n",
    "\n",
    "- Ensure the input file is named `Korea-ggumim.csv` and placed in the `Datasets/` directory.\n",
    "\"\"\"\n",
    "\n",
    "# Save README content to a file\n",
    "with open(\"README.md\", \"w\") as readme_file:\n",
    "    readme_file.write(readme_content)\n",
    "\n",
    "print(\"README.md created successfully!\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
